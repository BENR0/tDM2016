---
title: "Temporal Datamining WS 1"
author: "Benjamin Roesner"
output:
  html_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 7
    highlight: pygments
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 2
  pdf_document:
    toc: yes
---
------

```{r chunk options and functions, echo=FALSE, eval = TRUE}
#bibliography: lit.bib


#eval: evaluate code chunk true/false
#include: include chunk in ouput document true/false (code still evaluated and plots generated)
#echo: include source code true/
#error: true/false display error messages
#message: true/ false display messages
#warning: true/false display warning messages
#eval: true/false evaluate block -> use with variable eval_block
#cache: cache results -> use with variable cache_erg
#fig.cap = figNum("FIG CAPTION"): figure captions, with numbering by figNum function (see below)
#anchor = "figure": use with package kfigr to get inline reference to images with number by using function figr("NAME OF CHUNK WITH FIGURE")

#child = "file.Rmd": include file

#links
#[SECTION NAME][LINK NAME]

#citation
#[@LITSHORTNAME]

#figure number counter function
figNum = local({
  i = 0
  function(x) {
    i <<- i + 1
    paste('Figure ', i, ': ', x, sep = '')
  }
})


#flag to easily change evaluation of code blocks in results section
eval_block = TRUE
#flag if reading and plotting should be cached
cache_erg = FALSE

```

```{r load_packages,echo=FALSE, error=FALSE, message=FALSE, include=FALSE}
#load packages
packages <- c("tidyr","dplyr","lubridate","zoo","stringr","timeSeries", "tseries", "car", "AdaptGauss", "forecast", "kfigr", "knitr")
lapply(packages,library,character.only=TRUE)
#set prefix for figure numbering
opts_knit$set(kfigr.prefix = TRUE)
```


```{r load_data, echo=FALSE}
data <- read.table("../projekt_1/Chirimachay_NO3.lrn", skip = 4, header = TRUE, fill = TRUE)
data$HH <- str_pad(data$HH, 2, c("left"), "0")
data$Min <- str_pad(data$Min, 2, c("left"), "0")

data <- unite_(data, "time", c("HH", "Min"), sep = ":")
data <- unite_(data, "date", c("YYYY", "MM", "DD"), sep = "-")
data <- unite_(data, "datetime", c("date", "time" ), sep = " ")
data <- select(data, datetime, NNO3mgl)
data$datetime <- parse_date_time(data$datetime, order = "Ymd HM")
```
#### Überblick über die Variable
Zur Verschaffung eines ersten Eindrucks ist die Variable NO3 als einfacher xyplot geplottet.
Hierbei ist neben der Variabilität vor allem aufällig das der Datensatz Unterbrechungen hat
welche mit Null aufgefüllt wurden.
Darüber fällt auf das Betrachtung des Histograms wie auch des QQplots nicht von einer
Normalverteilung der Variablen ausgegangen werden kann.

```{r inspect_data_1, echo=FALSE, fig.cap = "Inspect data", anchor = "figure"}
#get visual impression of data
plot(data$NNO3mgl,pch = "l")
```


```{r inspect_data_1.1, echo=FALSE}
hist(data$NNO3mgl)
#check if data ist normal distributed
#shapiro test better (more stable), but in R limited to 10000 values.
#Kolmogorov-Smirnov: NH: sample comes from the same distribution => small p-value reject
ks.test(data$NNO3mgl, "pnorm")
ks.test(sqrt(data$NNO3mgl), "pnorm")
qqPlot(data$NNO3mgl)
```

Transformiert man die Variable mit der Quadratwurzel verbessert sich die Situation im Histogram
deutlich während im QQplot weiterhin deutlich wird das keine eindeutige Normalverteilung vorliegt.
```{r inspect_data_2, echo=FALSE}
#transforma data with square root
data$NNO3mglsqr <- (data$NNO3mgl)**(1/2)
hist(data$NNO3mglsqr)
qqPlot(data$NNO3mglsqr)
```

#### Einsatz eines Komponentenmodels
Nimmt man ein Gauss Mixturen Model zur Modellierung der Daten zur Hilfe ist eine deutliche
optische Verbesserung im QQplot zu erkennen. Dies trifft sowohl auf die transformierte
(zweiter Plot) wie auch die auf die untransfomierten (erster Plot) Variable zu. 
```{r gmm, echo=FALSE}
#without transformation
#ad <- AdaptGauss(data$NNO3mgl[data$NNO3mgl > 0])
Means1 <- c(.02408040, 0.06860637, 0.11612066)
SD1 <- c(0.01819860, 0.02348486, 0.02677794)
Weights1 <- c(0.459, 0.359, 0.182)
RMS1 <- 0.5876663
QQplotGMM(data$NNO3mgl[data$NNO3mgl > 0], Means = Means1, SDs = SD1, Weights = Weights1)

#with square root
#adsqr <- AdaptGauss(data$NNO3mglsqr[data$NNO3mglsqr > 0])
Means2 <- c(0.08703968, 0.19133716, 0.30680937)
SD2 <- c(0.0723900, 0.0508635, 0.0518160)
Weights2 <- c(0.237, 0.378, 0.385)
RMS2 <- 0.3624861
QQplotGMM(data$NNO3mglsqr[data$NNO3mglsqr > 0], Means = Means2, SDs = SD2, Weights = Weights2)
```

Jedoch ist das Model welches dem zweite Plot zugrunde liegt vorzuziehen da dieses
einen Niedriegeren RMS Error vorweisen kann (`r RMS2` gegenüber `r RMS1`).

#### Modellierung des Datensatzes
Zunächst ist zu beachten das als Voraussetzung für die Modellierung mittels
AM/ MA/ ARMA Modellen der Datensatz stationär sein muss. Hierzu ist zunächst
ein Dickey-Fuller test gemacht worden welcher mit einem default P-value von 0.01
sugerriert das die Daten hinreichend stationär sind aber unter Beachtung des xyplots
als nicht vertrauenswürdig eingestuft wird. Dies bestätigt sich, zumindest rein optisch
über den Plot der einfachen Differenzen.
```{r timeseries,echo=FALSE, warning=FALSE}
#create time series
data <- select(data, datetime, NNO3mglsqr)
tsdata <- read.zoo(data)

#test if data ist stationary with dickey fuller test
adf.test(tsdata, k=0)
#data should be stationary enough for modelling
#but still taking differences
tsdata <- diff(tsdata)
plot(tsdata)
#data stationary => d = 1
```

Somit kann für die durch zu führende Modellierung der Parameter d = 1 festgehalten werden.
Um zu entscheiden welches Modell für die Modellierung des Datensatzes geeignet ist und
gleichzeitig die Parameter dieses Modells fest zu legen sind jeweils ein ACF sowie PACF Plot
der einfachen Differenzen gemacht worden.

```{r acf_pacf, echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
#determining model components
Acf(tsdata, lag.max = 30)
#acf plot cuts of after 3 lag => Ma = 3
Pacf(tsdata, lag.max = 30)
#pacf cuts of at lag 1 => AR = 1
```

Es zeigt sich das als Ansatz für ein ARIMA Modell der Parameter p = 1 durch den Pacf Plot, welcher
nach Lag Eins gegen Null tendiert, sowie der Parameter q = 3, da im Acf Plot der Cutoff nach Lag 3
sichtbar ist, sinnvoll erscheinen.

Nach dem Fitten des Modells an den Datensatz mit den oben genannten Parametern werden zunächst die
Residuen geprüft. Hierbei stellt sich heraus das im Acf Plot der Residuen diese nicht alle
innerhalb des Threshold liegen. Ein nachfolgend ausgeführter Box-Ljung test (P-value: 0.798)
jedoch suggeriert das die Residuen möglicherweise als weißes Rauchen interpretiert werden können.
Ein Abschließender Blick auf den vergleichenden Plot der Daten und der modellierten Daten
zeigt das die obschon die Extreme (Ausreißer nach oben, Datenlücken) erstaunlich gut durch
die Modellierung wieder gegeben werden, jedoch im letzen Drittel des Datensatzes auch deutliche
Diskrepanzen auftreten.

```{r modelling,echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
fitarima <- Arima(tsdata, c(1,1,3), method = "ML", transform.pars = FALSE)
#check redsiduals
resid <- residuals(fitarima)
Acf(resid)
Box.test(resid, type = "Ljung")#
#in the acf plot not all values ar within the threshold but box test suggests that
#residuals can be considered white noise
#
plot(forecast(fitarima), col = "green")
lines(as.ts(tsdata), add = TRUE)

```