---
title: "Teporales Data Mining, SS 2016"
subtitle: "Projekt 2, Wissen aus Hydrologie"
author: "Benjamin Roesner, Marta Lemanczyk, Jiachun Zhang"
output:
  html_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 7
    highlight: pygments
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 3
  pdf_document:
    highlight: zenburn
    toc: yes
---


```{r chunk options and functions_jiachun, echo=FALSE, eval = FALSE}
#eval: evaluate code chunk true/false
#include: include chunk in ouput document true/false (code still evaluated and plots generated)
#echo: include source code true/
#error: true/false display error messages
#message: true/ false display messages
#warning: true/false display warning messages
#eval: true/false evaluate block -> use with variable eval_block
#cache: cache results -> use with variable cache_erg
#fig.cap = figNum("FIG CAPTION"): figure captions, with numbering by figNum function (see below)
#anchor = "figure": use with package kfigr to get inline reference to images with number by using function figr("NAME OF CHUNK WITH FIGURE")
#child = "file.Rmd": include file

#links
#[SECTION NAME][LINK NAME]

#citation from lit.bib
#[@LITSHORTNAME]

#figure number counter function


figNum = local({
  i = 0
  function(x) {
    i <<-  i + 1
    paste("Figure ", i, ": ", x, sep = "")
  }
})


#flag to easily change evaluation of code blocks in results section
eval_block <- FALSE
#flag if reading and plotting should be cached
cache_erg <- FALSE
```


```{r problem specific functions_jiachun, echo = FALSE, include = FALSE, eval=eval_block}
# Funktion, um die erste bzw.letzte 10 Ertraege zu sehen
printData <- function(data){
  print("Erste bzw. letzte 10 Werte des Datensatzes")
  #head(data,n=10)
  #tail(data, n = 10)
  print(data[1:10,])
  temp=nrow(data)
  print(data[(temp-10):temp,])
}

# Histogram,PDEplot,QQplot,Boxplot,NaN Anzahl
overviewPlot <- function(data, name = "data"){
  par(mfrow = c(2,3)) 
  #mat <- matrix(c(1,2,0,3,4,5),2,byrow = T)
  #layout(mat,c(5,5,1),c(1,1))
  
  MinD <- nanmin(data)
  MaxD <- nanmax(data)
  
  # Histogramm
  hist(data, ylab = "Nr of Data")
  
  # PDE-Dichte
  #PDEplot(data,title=name, xlab=name);  # Bei mir kann das Plot nicht verkleinert werden
  pdeVal <- ParetoDensityEstimation(data, ParetoRadius(data))
  plot(pdeVal$kernels, pdeVal$paretoDensity, type = "l", xlab = "Data", ylab = "PDE", main = name)
  #plot(density(data),main=name);
  
  plot.new()
  
  # QQplot
  qqnorm(data, ylab = name)
  gridOn()
  qqline(data, col="blue",lwd=3)
  
  # Boxplot
  boxplot(data, xlab=name, main = paste("Range:[ ", num2str(round(MinD, 5)), " ,", num2str(round(MaxD, 5)) ," ]"), axes = FALSE)
  
  
  # Barplot fuer die NaNs
  NaNs <- (sum(is.infinite(data)) + sum(is.na(data)))/length(data)
  barplot(NaNs, ylab = "NaNs in %", main = paste(round(NaNs, 4), " %"), xlim = c(0, 3), ylim = c(0, 1))
  if (any(is.nan(data), na.rm = TRUE)) 
    print("NaNs in Data found. This message is only important, if after rounding the percent of NaN is zero in the bar plot.")
  if (any(is.infinite(data), na.rm = TRUE)) 
    warning("Infinite values in Data found.")
  
  par(mfrow = c(1,1))
}

```

```{r load_packages_jiachun, echo=FALSE, error=FALSE, message=FALSE, include=FALSE,eval=eval_block}
#load packages
packages <- c('ABCanalysis','AdaptGauss','DataVisualisation','GabrielGraph','GabrielGraph','Umatrix','dbt.attributes','dbt.BDM','dbt.CART','ClassAnalysis','dbt.classifiers','dbt.ColorScale','dbt.ColorScale','DataIO','dbt.DelaunayVoronoi','Dist','dbt.Distances','dbt.DNAarrays','dbt.general','dbt.GraphAlgorithms','dbt.HESKES','dbt.IGCfiles','dbt.InteractiveTools','dbt.MixtureModel','dbt.nanHandling','dbt.NeuronalNets','pareto','dbt.Plot','dbt.Projections','dbt.RetroMAT','dbt.Statistics','reshape2','caTools','dbt.Transforms') #dbt Pakete
packages = c(packages,"kfigr", "knitr") #Pakete für knit
packages = c(packages,'FinTS','tseries') #Pakete für GARCH

lapply(packages,library,character.only=TRUE)

#set prefix for figure numbering
opts_knit$set(kfigr.prefix = TRUE)
```


```{r load, echo = FALSE}

#FileName <- c("p2_Chirimachay_NO3","p2_Chirimachay_Netradiation.lrn","p2_Chirimachay_Precip.lrn")
FileName <-c('Chirimachay_NO3','Chirimachay_Netradiation.lrn','Chirimachay_Precip.lrn')

## Pfad bitte hier anpassen!!!
#Directory  <- "../data/"
Directory <-'C:/#Private/Studium/SoSe 2016/Temporales Data Mining/Uebung/Zettel2'


NO3 <- ReadLRN(FileName[1],Directory)
#Netra <- ReadLRN(FileName[2],Directory)
Prec <- ReadLRN(FileName[3],Directory)

############################################################################
#NO3
attach(NO3)
```

# Inspizieren sie die einzelnen Zeitreihen mit den Methoden der Knowledge Discovery
Zur Untersuchung sind Datensätze „Chirimachay_NO3.lrn“ , „Chirimachay_Netradiation.lrn“ und „Chirimachay_Precip.lrn“.
Die Datensätze sind jeweils Liste mit 7 Variablen, so dass die Messungswerte und Messungszeiten genau notiert werden.

## Chirimachay_NO3
Zuerst untersuchen wir den Datensatz „Chirimachay_NO3.lrn“.
Die erste Erträge sowie die letzten Erträge der Variable NO3 sehen wie folgt aus:
```{r inspect vars, echo = FALSE}
# Messungsfrequenz
printData(Data)
```

Es sind insgesamt 22695 Werte, welche alle 30 Minuten von 10 Uhr (14.5.2014) bis 5 Uhr (30.8.2015) gemessen wurden.
Die Zeitreihe verläuft stetig, wobei einige Fehlstellen wahrscheinlich durch Interpolation ersetzt wurden,
da man einige Sprünge zwischen Zeitpunkten beobachten kann. Die Zeitreihe ist nicht stationär und auch nicht
heteroskedastisch, weshalb man annehmen kann, dass es sich nicht um weißes Rauschen handelt. Für die Verteilung der zeitunabhängigen
Beobachtungswerte „NNO3mgl“ wurden Histogramm, PDE plot, QQ-plot gegen Normalverteilung,
Boxplot sowie das Barplot für NaNs ausgegeben.
```{r overview, echo = FALSE, fig.cap = figNum("Ueberblick von Zeitreihe NO3")}
# Ueberblick von Zeitreihe
year <- Data[,3]
indy <- which(year == 2015, arr.ind = T)

plot(Data[, 1], type="l", ylab = "NO3", xlab = "Zeit", col = "blue")
abline(v = min(indy), col = c("red"),  lwd = 3)
```


```{r overview_Verteilung, echo = FALSE, fig.cap = figNum("Visuelle Inspektion NO3")}
# Verteilungsbetrachtung
#library("reshape2")
#library("caTools")
#par(mfrow=c(2,3))
#InspectVariable(Data[,1],Header[1])  # Muss zuerst Pakete importieren. 
#par(mfrow=c(1,1))                    #Bei mir kann die Graphiken nicht innerhalb ein Bild legen. Version von R?

overviewPlot(Data[, 1], Header[1])
```

Der Datensatz erhält keine NaNs, jedoch relativ viele Nullen. Deshalb vermuten wir, dass Messfehler oder -lücken durch Nullen ersetzt wurden. Der Wertebereich der Daten ist sehr klein. Die Daten sind nicht normalverteilt.

Wir betrachten den Datensatz jetzt noch einmal ohne die Nullen.
```{r inspect var ohne null, echo = FALSE, fig.cap = figNum("Visuelle Inspektion NO3 ohne Nullen")}
# Eliminierung der Nullen  
ohneNull <- Data[, 1][Data[, 1] != 0]

overviewPlot(ohneNull, paste(Header[1], "ohne Null"))
```

Nach Eliminierung der Nullen ist es deutlich, dass es sich um Wachstum handelt. -> logaritmieren?
Aufgrund des kleinen Wertebereiches multiplizieren wir die Daten mit dem Faktor 100. Außerdem werden die Daten logarithmiert.

Nach mehrfacher Durchführung der Box-Cox Transformation erhielten wir Lambda = 0,5, weshalb wir die Wurzel von den Daten gezogen haben.
```{r boxcoxTras, echo = FALSE,warning=FALSE, fig.cap = figNum("Eine der Ergebnissse bei Box-Cox Power Transformation")}
# Transformieren Daten, um Normalverteilung zu annaehren
#### aus welchem Paket ist boxcoxTrans??? dbt.Transforms
boxcoxTrans(ohneNull[sample(1:length(ohneNull), 5000)])
```

Die Wurzel-Transformation (Wurzel(Daten)*100):
```{r inspect var trafo 2, echo = FALSE,fig.cap = figNum("Visuelle Inspektion transformierte NO3 ohne Nullen")}
#transNO3 <- slog(ohneNull)*100
#transNO3 <- slog(1/ohneNull)
transNO3 <- (sqrt(ohneNull) * 100)
overviewPlot(transNO3, paste("Transformierte", Header[1]))
```

Bei kleineren Werten bietet die Approximationen keine guten Werte, weshalb wir ein Gaussian Mixture Modell anwenden.


***   
### GMM
```{r GMM, echo = FALSE, eval = eval_block}
temp <- AdaptGauss(transNO3)

Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
res1 <- AdaptGauss(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights)
dput(res1)
ab <- Bayes4Mixtures(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights, PlotIt = T) 
```

```{r GMM plot, echo = FALSE,fig.cap = figNum("GMM für tranformierte NO3 ohne Nullen, 3 Gauss"),eval = eval_block}
Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
res1 <- AdaptGauss(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights)
```

```{r gmm verification plot, echo = FALSE, fig.cap = figNum("QQplot zur Verifizierung, Daten gegen GMM")}
#Verifizierung
Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
QQplotGMM(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights)

```

Hier sieht man, dass die Anpassung bei der extrem Werte Bereich immer noch schlecht ist.
Betrachte noch die statistische Verifizierung.

```{r gmm verification statistik test, echo = FALSE,fig.cap = figNum("Chi-Quadrat-Test. H0: Daten und GMM besitzen die gleiche Verteilung")}

abc <- Chi2testMixtures(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights, PlotIt = T)
```

P-Wert ist in der Tat sehr groß, H0 wrid nicht abgeleht. Anpassung gut.

***
### Clusterung der Daten
Die Beobachtung kann zu vier Klassen geteilt werden, Niedrige Stoffkonzentration,
mittele Stoffkonzentration hoch Stoffkonzentration sowie die Nullen.


```{r clusterung, echo = FALSE, fig.cap = figNum("Clusterung nach GMM, Nullen bilden sich als eine Gruppe")}
#Clusterung
dec <- BayesDecisionBoundaries(Werte1$Means, Werte1$SDs, Werte1$Weights)
Cls <- ClassifyByDecisionBoundaries(transNO3, dec)

ind <- which(Data[, 1] != 0)
ind2 <- which(Data[, 1] == 0)

plot(ind, Data[ind, 1], ylab = "NO3", xlab = "Zeit", col = Cls, main = "Clusterung", ylim = c(-0, 0.4))
points(ind2, Data[ind2, 1], col = "blue")
abline(v = min(indy), col = c("pink"), lwd = 3)
legend("topright", c("Hoch", "Mittel", "Niedrig", "Null"), col = c("green", "red", "black", "blue"), pch = 1)


detach(NO3)

```

***
### ARCH/GARCH
Betrachte Differenzreihe, da die Zeitreihe stationär sein muss.
```{r Stationärität, echo = FALSE}
data <- NO3$Data[,1]
Differenz <- diff(data)
```

ARCH LM-Test, teste, ob ARCH Effekte gibt:
```{r Arch/ Garch, echo = FALSE, include = TRUE}
#Beste AR Modell Schatzen, Berechne die Regression der Yt-1 auf die Yt (KQ) um die Fehler e_t zu erhalten
#Berechne die KQ Regression von Fehler
#Teste die gegenseitige Signifikanz der Parameter
#Falls einige dieser Koeffizienten signifikant konstruiere ein entsprechendes ARCH Modell

#acfpacfPlot(Differenz)
#acfpacfPlot(Differenz^2)

ArchTest(Differenz)
```

Nullhypothese wird abgelehnt, es gibt ARCH Effekt.

Die Parameter wird hier durch Anprobieren bestimmt, dann durch AIC Kriterium das beste Parameter bestimmt.

```{r Arch/ Garch 2, echo = FALSE, message = FALSE, include = FALSE}
gar1 <- garch(Differenz,order = c(1,0))
gar2 <- garch(Differenz,order = c(2,0))
gar3 <- garch(Differenz,order = c(3,0))
gar4 <- garch(Differenz,order = c(1,1))
gar5 <- garch(Differenz,order = c(1,2))
gar6 <- garch(Differenz,order = c(2,1))
gar7 <- garch(Differenz,order = c(2,2))
aic <- c()
aic <- c(aic,AIC(gar1))
aic <- c(aic,AIC(gar2))
aic <- c(aic,AIC(gar3))
aic <- c(aic,AIC(gar4))
aic <- c(aic,AIC(gar5))
aic <- c(aic,AIC(gar6))
aic <- c(aic,AIC(gar7))
```

```{r Arch/ Garch plot, echo = FALSE, fig.cap = figNum("Güte des GARCH Modelles mit unterschiedliche Parameter")}
plot(aic, type = "l")
points(aic)
legend("topright", paste(1:7, ": GARCH(",c("1,0","2,0","3,0","1,1","1,2","2,1","2,2"),")"), pch = 1)
```

Also hier wird GARCH(1,1) ausgewählt.

```{r Arch/ Garch 3, echo = FALSE,fig.cap = figNum("Residuenanalysis für GARCH(1,1)")}
summary(gar4)

#Jarque Bera Test: test, ob Residuals normalverteilt ist.
#Residual soll Chi2 verteilt ist --> heavy tail
#Box-Ljung test: test,ob Autokorrelation gibt.
#Residual soll kein Autokorrelation vorliegen

#plot(gar4)
overviewPlot(gar4$residuals, "Residuen für GARCH(1,1)")

```

Jarque Bera Test ist ein statistischer Test, der anhand der Schiefe und der Kurtosis in den Daten prüft,
ob eine Normalverteilung vorliegt. Hier zeigt, dass die Residuen keine Normalverteilung ist.
**Nach des Skripts muss Residuen $\chi^2$ verteilt sein.**
Die PDEplot zeigt keine $\chi^2$ Verteilung.

Box-Ljung Test testet auf der Autokorelation, hier zeigt keine Autokorelation innerhalb der Residuen.
Laut des Skripts sollen Risiduen keine Autokorrelation unterliegen, daher stellt das GARCH(1,1) 
eine gute Anpassung dar.



## Chirimachay_Precip
Jetzt untersuchen wir den Datensatz „Chirimachay_Precip.lrn“.
Die erste Erträge sowie die letzten Erträge der Variable NO3 sehen wie folgt aus:
```{r inspect vars_Precip, echo = FALSE}
attach(Prec)

# Messungsfrequenz
printData(Data)

```

Es sind insgesamt `r length(Data[,1])` Werte jede 30 Minuten von 13:30 Uhr, 3.1.2014 bis 8 Uhr, 14.12.2015 gemessen worden.
Meisten Daten sind entweder 0,0 oder 0,1. Geneuer ist `r round(length(Data[,1][Data[,1]==0])/length(Data[,1])*100)`% der Daten 0,0, und `r round(length(Data[,1][Data[,1]==0.1])/length(Data[,1])*100)`% der Daten hat der Wert 0,1.

```{r overview_Precip, echo = FALSE, fig.cap = figNum("Ueberblick von Zeitreihe Precipitation")}

# Ueberblick von Zeitreihe
year <- Data[,3]
indy <- which(year == 2015, arr.ind = T)

plot(Data[, 1], type="p", ylab = "Precip", xlab = "Zeit", col = "blue")
abline(v = min(indy), col = c("red"),  lwd = 3)
```

Für die Verteilung der zeitunabhängige
Beobachtungswerte „PrecipitationMM“ wirde folgende Histogramm, PDE plot, QQ-plot gegen Normalverteilung,
Boxplot sowie das Barplot für NaNs ausgegeben.
```{r overview_Verteilung_Precip, echo = FALSE, fig.cap = figNum("Visuelle Inspektion Precipitation")}
# Verteilungsbetrachtung
#library("reshape2")
#library("caTools")
#par(mfrow=c(2,3))
#InspectVariable(Data[,1],Header[1])  # Muss zuerst Pakete importieren. 
#par(mfrow=c(1,1))                    #Bei mir kann die Graphiken nicht innerhalb ein Bild legen. Version von R?

overviewPlot(Data[, 1], Header[1])
```

 - Keine NaNs, Es gibt ganz vielen 0,0 und 0,1.
 - Wertbereich sehr klein.
 
Versuche jetzt die Nullen und 0,1 wegzunehmen.
```{r inspect var ohne null_Precip, echo = FALSE, fig.cap = figNum("Visuelle Inspektion Precipitation ohne 0,0 und 0,1. Transformierte Precipitation")}
# Eliminierung der Nullen und extrem kleinen Werten 
ohneNull <- Data[, 1][Data[, 1] != 0]
ohneNullklein <- ohneNull[ohneNull!= 0.1]

overviewPlot(ohneNullklein, paste(Header[1], "ohne 0,0 und 0,1"))
```

 - nach Eliminierung der 0,0 und 0,1 ist der Werte immer noch nicht normalverteilt, Transformation benötigt.
 - Wertbereich sehr klein, evtl.prozentuierung.

Nach mehrfach Durfühung der Box-cox Transformation hat Faktor -3,5 als Empfehlung erhalten:
```{r boxcoxTras_Precip, echo = FALSE,warning=FALSE, fig.cap = figNum("Eine der Ergebnissse bei Box-Cox Power Transformation")}
# Transformieren Daten, um Normalverteilung zu annaehren
#### aus welchem Paket ist boxcoxTrans??? dbt.Transforms
boxcoxTrans(ohneNullklein)
```

Betrachte daher die Transformation Daten^(-3)
```{r inspect var trafo 2_Precip, echo = FALSE,fig.cap = figNum("Visuelle Inspektion transformierte Precipitation ohne 0,0 und 0,1.")}

transPrec <- ohneNullklein^(-3)
overviewPlot(transPrec, paste("Transformierte", Header[1]))
```

 - 	Die Approximation in der Mitte sehr gut, am Rand ist die Approximation sehr schlecht.
    Muss erneut angepasst werden.
 -  Gaussian Mixture Modell
 
 ***   
### GMM
```{r GMM_Precip, echo = FALSE, eval = eval_block}
temp <- AdaptGauss(transPrec)

Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))

res2 <- AdaptGauss(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights)
dput(res2)
ab <- Bayes4Mixtures(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights, PlotIt = T) 
```

```{r GMM plot_Precip, echo = FALSE,fig.cap = figNum("GMM für tranformierte Precipitation ohne 0,0 und 0,1, 3 Gauss"),eval = eval_block}
Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))
res2 <- AdaptGauss(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights)
```

```{r gmm verification plot_Precip, echo = FALSE, fig.cap = figNum("QQplot zur Verifizierung, Daten gegen GMM")}
#Verifizierung
Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))
QQplotGMM(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights)

```

Hier sieht die Anpassung sehr gut. Führe noch statistische Verifizierung durch.

```{r gmm verification statistik test_Precip, echo = FALSE,fig.cap = figNum("Chi-Quadrat-Test. H0: Daten und GMM besitzen die gleiche Verteilung")}

abc <- Chi2testMixtures(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights, PlotIt = T)
```

P-Wert ist in der Tat sehr groß, da Stichproumfang sehr klein ist,`r length(transPrec)` wrid $H_0$ nicht abgeleht. Anpassung gut.

***
### Clusterung der Daten
Die Beobachtung kann zu fünf Klassen geteilt werden, Niedrige Precipitation, mittele Precipitation hoch Precipitation sowie die Nullen und standard Werte 0,1.


```{r clusterung_Precip, echo = FALSE, fig.cap = figNum("Clusterung nach GMM, 0,0 und 0,1 bilden sich jeweils als eine Gruppe")}
#Clusterung
dec <- BayesDecisionBoundaries(Werte2$Means, Werte2$SDs, Werte2$Weights)
Cls <- ClassifyByDecisionBoundaries(transPrec, dec)

ind <- which(Data[, 1] > 0.1)
ind2 <- which(Data[, 1] == 0)
ind3 <- which(Data[, 1] == 0.1)

plot(ind, Data[ind, 1], ylab = "Precipitation", xlab = "Zeit", col = Cls, main = "Clusterung", ylim = c(0,1))
points(ind2, Data[ind2, 1], col = "blue")
points(ind3, Data[ind3, 1], col = "pink")
abline(v = min(indy), col = 6, lwd = 3)
legend("topright", c("Hoch", "Mittel", "Niedrig","0,1", "0.0"), col = c("green", "red", "black", "pink","blue"), pch = 1)


detach(Prec)

```

***


# Beschreiben Sie den Wissensgewinn durch diese Modelle. Wie und wodurch wird NO3 beeinflusst?

