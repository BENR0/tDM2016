---
title: "Teporales Data Mining, SS 2016"
subtitle: "Projekt 2, Wissen aus Hydrologie"
author: "Benjamin Roesner, Marta Lemanczyk, Jiachun Zhang"
output:
  html_document:
    css: style.css
    fig_caption: yes
    fig_retina: 1
    fig_height: 5
    fig_width: 7
    highlight: pygments
    number_sections: yes
    theme: united
    keep_md: no
    toc: yes
    toc_depth: 3
  pdf_document:
    highlight: zenburn
    toc: yes
---


```{r chunk options and functions_jiachun, echo=FALSE}
#eval: evaluate code chunk true/false
#include: include chunk in ouput document true/false (code still evaluated and plots generated)
#echo: include source code true/
#error: true/false display error messages
#message: true/ false display messages
#warning: true/false display warning messages
#eval: true/false evaluate block -> use with variable eval_block
#cache: cache results -> use with variable cache_erg
#fig.cap = figNum("FIG CAPTION"): figure captions, with numbering by figNum function (see below)
#anchor = "figure": use with package kfigr to get inline reference to images with number by using function figr("NAME OF CHUNK WITH FIGURE")
#child = "file.Rmd": include file

#links
#[SECTION NAME][LINK NAME]

#citation from lit.bib
#[@LITSHORTNAME]

#figure number counter function


figNum = local({
  i = 0
  function(x) {
    i <<-  i + 1
    paste("Figure ", i, ": ", x, sep = "")
  }
})


#flag to easily change evaluation of code blocks in results section
eval_block <- FALSE
#flag if reading and plotting should be cached
cache_erg <- FALSE
```


```{r problem specific functions_jiachun, echo = FALSE, include = FALSE}
# Funktion, um die erste bzw.letzte 10 Ertraege zu sehen
printData <- function(data){
  print("Erste bzw. letzte 10 Werte des Datensatzes")
  #head(data,n=10)
  #tail(data, n = 10)
  print(data[1:10,])
  temp=nrow(data)
  print(data[(temp-10):temp,])
}

# Histogram,PDEplot,QQplot,Boxplot,NaN Anzahl
overviewPlot <- function(data, name = "data"){
  par(mfrow = c(2,3)) 
  #mat <- matrix(c(1,2,0,3,4,5),2,byrow = T)
  #layout(mat,c(5,5,1),c(1,1))
  
  MinD <- nanmin(data)
  MaxD <- nanmax(data)
  
  # Histogramm
  hist(data, ylab = "Nr of Data")
  
  # PDE-Dichte
  #PDEplot(data,title=name, xlab=name);  # Bei mir kann das Plot nicht verkleinert werden
  pdeVal <- ParetoDensityEstimation(data, ParetoRadius(data))
  plot(pdeVal$kernels, pdeVal$paretoDensity, type = "l", xlab = "Data", ylab = "PDE", main = name)
  #plot(density(data),main=name);
  
  plot.new()
  
  # QQplot
  qqnorm(data, ylab = name)
  gridOn()
  qqline(data, col="blue",lwd=3)
  
  # Boxplot
  boxplot(data, xlab=name, main = paste("Range:[ ", num2str(round(MinD, 5)), " ,", num2str(round(MaxD, 5)) ," ]"), axes = FALSE)
  
  
  # Barplot fuer die NaNs
  NaNs <- (sum(is.infinite(data)) + sum(is.na(data)))/length(data)
  barplot(NaNs, ylab = "NaNs in %", main = paste(round(NaNs, 4), " %"), xlim = c(0, 3), ylim = c(0, 1))
  if (any(is.nan(data), na.rm = TRUE)) 
    print("NaNs in Data found. This message is only important, if after rounding the percent of NaN is zero in the bar plot.")
  if (any(is.infinite(data), na.rm = TRUE)) 
    warning("Infinite values in Data found.")
  
  par(mfrow = c(1,1))
}

```

```{r load_packages_jiachun, echo=FALSE, error=FALSE, message=FALSE, include=FALSE}
#load packages
packages <- c('ABCanalysis','AdaptGauss','DataVisualisation','dbt.attributes','dbt.BDM','dbt.CART'
              ,'ClassAnalysis','dbt.classifiers','dbt.ColorScale','dbt.ColorScale','DataIO',
              'dbt.DelaunayVoronoi','dbt.Distances','dbt.DNAarrays','dbt.general','dbt.GraphAlgorithms'
              ,'dbt.HESKES','dbt.IGCfiles','dbt.InteractiveTools','dbt.MixtureModel','dbt.nanHandling'
              ,'dbt.NeuronalNets','dbt.Plot','dbt.Projections','dbt.RetroMAT','dbt.Statistics'
              ,'reshape2','caTools','dbt.Transforms', 'DataIO') #dbt Pakete
packages = c(packages,"kfigr", "knitr") #Pakete für knit
packages = c(packages,'FinTS','tseries') #Pakete für GARCH

lapply(packages,library,character.only=TRUE)

#set prefix for figure numbering
opts_knit$set(kfigr.prefix = TRUE)
```


```{r load, echo = FALSE}

FileName <- c("p2_Chirimachay_NO3.lrn","p2_Chirimachay_Netradiation.lrn","p2_Chirimachay_Precip.lrn")
#FileName <-c('P2_Chirimachay_NO3','Chirimachay_Netradiation.lrn','Chirimachay_Precip.lrn')

## Pfad bitte hier anpassen!!!
Directory  <- "../data/"
#Directory <-'C:/#Private/Studium/SoSe 2016/Temporales Data Mining/Uebung/Zettel2'


NO3 <- ReadLRN(FileName[1],Directory)
#Netra <- ReadLRN(FileName[2],Directory)
Prec <- ReadLRN(FileName[3],Directory)

############################################################################
#NO3
attach(NO3)
```

# Inspizieren sie die einzelnen Zeitreihen mit den Methoden der Knowledge Discovery
Zur Untersuchung sind Datensätze „Chirimachay_NO3.lrn“ , „Chirimachay_Netradiation.lrn“ und „Chirimachay_Precip.lrn“.
Die Datensätze sind jeweils Liste mit 7 Variablen, so dass die Messungswerte und Messungszeiten genau notiert werden.

## Chirimachay_NO3
Zuerst untersuchen wir den Datensatz „Chirimachay_NO3.lrn“.
Die erste Erträge sowie die letzten Erträge der Variable NO3 sehen wie folgt aus:
```{r inspect_vars, echo = FALSE}
# Messungsfrequenz
printData(Data)
```

Es sind insgesamt 22695 Werte, welche alle 30 Minuten von 10 Uhr (14.5.2014) bis 5 Uhr (30.8.2015) gemessen wurden.
Die Zeitreihe verläuft stetig, wobei einige Fehlstellen wahrscheinlich durch Interpolation ersetzt wurden,
da man einige Sprünge zwischen Zeitpunkten beobachten kann. Die Zeitreihe ist nicht stationär und heteroskedastisch, weshalb man annehmen kann, dass es sich nicht um weißes Rauschen handelt. 

```{r overview, echo = FALSE, fig.cap = figNum("Überblick der Zeitreihe NO3")}
# Ueberblick von Zeitreihe
year <- Data[,3]
indy <- which(year == 2015, arr.ind = T)

plot(Data[, 1], type="l", ylab = "NO3", xlab = "Zeit", col = "blue")
abline(v = min(indy), col = c("red"),  lwd = 3)
```

Für die Verteilung der zeitunabhängigen
Beobachtungswerte „NNO3mgl“ wurden Histogramm, PDE plot, QQ-plot gegen Normalverteilung,
Boxplot sowie das Barplot für NaNs ausgegeben.

```{r overview_Verteilung, echo = FALSE, fig.cap = figNum("Visuelle Inspektion NO3")}
# Verteilungsbetrachtung
#library("reshape2")
#library("caTools")
#par(mfrow=c(2,3))
#InspectVariable(Data[,1],Header[1])  # Muss zuerst Pakete importieren. 
#par(mfrow=c(1,1))                    #Bei mir kann die Graphiken nicht innerhalb ein Bild legen. Version von R?

overviewPlot(Data[, 1], Header[1])
```

Der Datensatz erhält keine NaNs, jedoch relativ viele Nullen. Deshalb vermuten wir, dass Messfehler oder -lücken durch Nullen ersetzt wurden. Der Wertebereich der Daten ist sehr klein. Die Daten sind nicht normalverteilt.

Wir betrachten den Datensatz jetzt noch einmal ohne die Nullen.

```{r inspect_var_ohne_null, echo = FALSE, fig.cap = figNum("Visuelle Inspektion NO3 ohne Nullen")}
# Eliminierung der Nullen  
ohneNull <- Data[, 1][Data[, 1] != 0]

overviewPlot(ohneNull, paste(Header[1], "ohne Null"))
```

Nach Eliminierung der Nullen ist es deutlich, dass es sich um Wachstum handelt.
Aufgrund des kleinen Wertebereiches multiplizieren wir die Daten mit dem Faktor 100.

Nach mehrfacher Durchführung der Box-Cox Transformation erhielten wir Lambda = 0,5, weshalb wir die Wurzel von den Daten gezogen haben.

```{r boxcoxTras, echo = FALSE, warning=FALSE, fig.cap = figNum("Eines der Ergebnisse bei Box-Cox Power Transformation")}
# Transformieren Daten, um Normalverteilung zu annaehren
#### aus welchem Paket ist boxcoxTrans??? dbt.Transforms
#boxcoxTrans(ohneNull[sample(1:length(ohneNull), 5000)])
```

Die Wurzel-Transformation (Wurzel(Daten)*100):

```{r inspect_var_trafo_2, echo = FALSE,fig.cap = figNum("Visuelle Inspektion transformierte NO3 ohne Nullen")}
#transNO3 <- slog(ohneNull)*100
#transNO3 <- slog(1/ohneNull)
transNO3 <- (sqrt(ohneNull) * 100)
overviewPlot(transNO3, paste("Transformierte", Header[1]))
```

Bei kleineren Werten bietet die Approximationen keine guten Werte, weshalb wir ein Gaussian Mixture Modell anwenden.
***
### GMM
```{r GMM, echo = FALSE, eval = eval_block}
temp <- AdaptGauss(transNO3)

Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
res1 <- AdaptGauss(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights)
dput(res1)
ab <- Bayes4Mixtures(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights, PlotIt = T) 
```

Wir passen die transformierte Daten mit 3 Gauss und verifizieren die Anpassung mit QQ-plot.

```{r GMM_plot, echo = FALSE,fig.cap = figNum("GMM für tranformierte NO3 ohne Nullen, 3 Gauss")}
Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
PlotMixturesAndBoundaries(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights,SingleGausses=T, lwd=3)
```


```{r gmm_verification_plot, echo = FALSE, fig.cap = figNum("QQplot zur Verifizierung, Daten gegen GMM")}
#Verifizierung
Werte1 <- list(Means = c(7.029219, 17.786148, 29.106267), 
           SDs = c(5.08932, 4.50063, 5.69700), 
           Weights = c( 0.176, 0.348, 0.490))
QQplotGMM(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights)

```

Die Anpassung sieht im QQ-Plot bis auf die Werte am Rand gut aus. Zur statistischen Verifizierung verwenden wir noch den Chi-Quadrat-Test.

```{r gmm_verification_statistik_test, echo = FALSE,fig.cap = figNum("Chi-Quadrat-Test. Nullhypothese: Daten und GMM besitzen die gleiche Verteilung")}

abc <- Chi2testMixtures(transNO3, Werte1$Means, Werte1$SDs, Werte1$Weights, PlotIt = T)
```

Der $\beta$-Wert aus der Chi2testMixures Funktion liefert einen sehr kleinen Wert, daher ist der P-Value fast 1, $H_0$ wrid nicht abgeleht. Das Modell ist statistisch mit GMM gut angepasst.

***
### Clusterung der Daten
Mit Hilfe des Gauss-Mixturen-Models haben wir die beobachteten Daten in 3 Klassen eingeteilt:
Niedrige, mittlere und hohe Stoffkonzentration. Zusätzlich haben wir die Nullen noch eingezeichnet.

```{r clusterung, echo = FALSE, fig.cap = figNum("Clusterung nach GMM, Nullen bilden eine eigene Gruppe")}
#Clusterung
dec <- BayesDecisionBoundaries(Werte1$Means, Werte1$SDs, Werte1$Weights)
Cls <- ClassifyByDecisionBoundaries(transNO3, dec)

ind <- which(Data[, 1] != 0)
ind2 <- which(Data[, 1] == 0)

plot(ind, Data[ind, 1], ylab = "NO3", xlab = "Zeit", col = Cls, main = "Clusterung", ylim = c(-0, 0.4))
points(ind2, Data[ind2, 1], col = "blue")
abline(v = min(indy), col = c("pink"), lwd = 3)
legend("topright", c("Hoch", "Mittel", "Niedrig", "Null"), col = c("green", "red", "black", "blue"), pch = 1)


detach(NO3)

```

***
### ARCH/GARCH
An dieser Stelle versuchen wir noch den Datensatz mit ARCH/GARCH Modell anzupassen. Hierfür bilden wir zuerst die Differenzreihe, da die Zeitreihe stationär sein muss.
```{r Stationärität, echo = FALSE}
data <- NO3$Data[,1]
Differenz <- diff(data)
```

Hier wird der ARCH LM-Test verwendet und überprüft, ob es ARCH Effekte gibt.

```{r Arch_Garch, echo = FALSE, include = TRUE}
#Beste AR Modell Schatzen, Berechne die Regression der Yt-1 auf die Yt (KQ) um die Fehler e_t zu erhalten
#Berechne die KQ Regression von Fehler
#Teste die gegenseitige Signifikanz der Parameter
#Falls einige dieser Koeffizienten signifikant konstruiere ein entsprechendes ARCH Modell

#acfpacfPlot(Differenz)
#acfpacfPlot(Differenz^2)

ArchTest(Differenz)
```

Wegen des kleines P-Wert wird die Nullhypothese abgelehnt, d.h. es gibt einen ARCH Effekt.

Die Parameter werden hier durch Ausprobieren bestimmt. Anschließend wird mit Hilfe des AIC-Kriteriums der beste Parameter bestimmt.

```{r Arch_Garch_2, echo = FALSE, message = FALSE, include = FALSE}
gar1 <- garch(Differenz,order = c(1,0))
gar2 <- garch(Differenz,order = c(2,0))
gar3 <- garch(Differenz,order = c(3,0))
gar4 <- garch(Differenz,order = c(1,1))
gar5 <- garch(Differenz,order = c(1,2))
gar6 <- garch(Differenz,order = c(2,1))
gar7 <- garch(Differenz,order = c(2,2))
aic <- c()
aic <- c(aic,AIC(gar1))
aic <- c(aic,AIC(gar2))
aic <- c(aic,AIC(gar3))
aic <- c(aic,AIC(gar4))
aic <- c(aic,AIC(gar5))
aic <- c(aic,AIC(gar6))
aic <- c(aic,AIC(gar7))
```

```{r Arch_Garch_plot, echo = FALSE, fig.cap = figNum("Güte des GARCH Modelles mit unterschiedlichen Parametern")}
plot(aic, type = "l")
points(aic)
legend("topright", paste(1:7, ": GARCH(",c("1,0","2,0","3,0","1,1","1,2","2,1","2,2"),")"), pch = 1)
```

Wir sehen, dass der Wert beim AIC für einen GARCH(1,1) am geringsten ist, weshalb dieser ausgewählt wird.

```{r Arch_Garch_3, echo = FALSE,fig.cap = figNum("Residuenanalysis für GARCH(1,1)")}
summary(gar4)

#Jarque Bera Test: test, ob Residuals normalverteilt ist.
#Residual soll Chi2 verteilt ist --> heavy tail
#Box-Ljung test: test,ob Autokorrelation gibt.
#Residual soll kein Autokorrelation vorliegen

#plot(gar4)
overviewPlot(gar4$residuals, "Residuen für GARCH(1,1)")

```

Jarque-Bera-Test ist ein statistischer Test, der anhand der Schiefe und der Kurtosis in den Daten prüft,
ob eine Normalverteilung vorliegt. Hier zeigt es sich, dass die Residuen nicht normalverteilt sind.
**Den Vorlesungsunterlagen nach müssen die Residuen $\chi^2$ verteilt sein.**
Die PDEplot zeigt keine $\chi^2$ Verteilung.

Box-Ljung Test überprüft, ob innerhalb der Residuen eine Autokorrelation existiert. In den Residuen dieses Datensatzes ist eher keine Autokorrekation zu finden.
Laut Skript sollen Residuen nicht autokorreliert sein, weshalb wie die GARCH(1,1) Anpassung als gut einstufen.


## Chirimachay_Precip
Jetzt untersuchen wir den Datensatz „Chirimachay_Precip.lrn“.
Die ersten sowie letzten Einträge der Variable Precip sehen wie folgt aus:
```{r inspect_vars_Precip, echo = FALSE}
attach(Prec)

# Messungsfrequenz
printData(Data)

```

Es sind insgesamt `r length(Data[,1])` Werte, die wie bei unserem vorherigen Datensatz N03 alle 30 Minuten von 13:30 Uhr (3.1.2014) bis 8 Uhr (14.12.2015) gemessen worden sind.
Ein Großteil der Daten haben entweder einen Wert von 0 oder 0,1. Genauer gesagt ist `r round(length(Data[,1][Data[,1]==0])/length(Data[,1])*100)`% der Daten 0 und `r round(length(Data[,1][Data[,1]==0.1])/length(Data[,1])*100)`% der Daten haben den Wert 0,1.

Die Zeitreihe ist außerdem nicht stetig, es gibt keine Werte zwischen 0 und 0,1. Die Zeitreihe ist nicht stationär, heteroskedastisch, daher auch kein weißes Rauschen.

```{r overview_Precip, echo = FALSE, fig.cap = figNum("Überblick der Zeitreihe Precipitation")}

# Ueberblick von Zeitreihe
year <- Data[,3]
indy <- which(year == 2015, arr.ind = T)

plot(Data[, 1], type="p", ylab = "Precip", xlab = "Zeit", col = "blue")
abline(v = min(indy), col = c("red"),  lwd = 3)
```

Für die Verteilung der zeitunabhängigen Beobachtungswerte „PrecipitationMM“ wurden ebenso Histogramm, PDE plot, QQ-plot gegen Normalverteilung, Boxplot sowie der Barplot für NaNs betrachtet.
```{r overview_Verteilung_Precip, echo = FALSE, fig.cap = figNum("Visuelle Inspektion Precipitation")}
# Verteilungsbetrachtung
#library("reshape2")
#library("caTools")
#par(mfrow=c(2,3))
#InspectVariable(Data[,1],Header[1])  # Muss zuerst Pakete importieren. 
#par(mfrow=c(1,1))                    #Bei mir kann die Graphiken nicht innerhalb ein Bild legen. Version von R?

overviewPlot(Data[, 1], Header[1])
```

Auch dieser Datensatz entält keine NaNs, jedoch viele Nullen und Werte von 0,1. Der Wertebereich ist klein.

Wir haben die Nullen und die 0,1 Werte als seperate Gruppen aus dem Datensatz genommen und betrachten nun die restlichen Daten. Beachte hier, dass der Stichprobumfang der restlichen Daten sehr klein ist, die Verteilung von nur 366 Daten wird untersucht.

```{r inspect_var_ohne_null_Precip, echo = FALSE, fig.cap = figNum("Visuelle Inspektion Precipitation ohne 0,0 und 0,1. Transformierte Precipitation")}
# Eliminierung der Nullen und extrem kleinen Werten 
ohneNull <- Data[, 1][Data[, 1] != 0]
ohneNullklein <- ohneNull[ohneNull!= 0.1]

overviewPlot(ohneNullklein, paste(Header[1], "ohne 0,0 und 0,1"))
```

Die restlichen Daten sind weiterhin nicht normalverteilt, weshalb wir die Daten transformieren.

Nach mehrfacher Durchführung der Box-Cox-Transformation erhielten wir ein Lambda = -3,5. Nach Tukeys Ladder of Power entscheiden wir uns daher die Daten mit -3 zu potenzieren.

```{r boxcoxTrans_Precip, echo = FALSE,warning=FALSE, fig.cap = figNum("Eine der Ergebnissse bei Box-Cox Power Transformation")}
# Transformieren Daten, um Normalverteilung zu annaehren
#### aus welchem Paket ist boxcoxTrans??? dbt.Transforms
#boxcoxTrans(ohneNullklein)
```

Transformatierte Daten (Daten^(-3)):

```{r inspect_var_trafo_2_Precip, echo = FALSE,fig.cap = figNum("Visuelle Inspektion transformierter Precipitation Daten ohne 0,0 und 0,1.")}

transPrec <- ohneNullklein^(-3)
overviewPlot(transPrec, paste("Transformierte", Header[1]))
```

Die Anpassung ist noch nicht ganz zufriedenstellend, da die Werte am Rand sehr stark abweichen. Deshalb verwenden wir wieder das GMM.
 
 ***   
### GMM
```{r GMM_Precip, echo = FALSE, eval = eval_block}
temp <- AdaptGauss(transPrec)

Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))

res2 <- AdaptGauss(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights)
dput(res2)
ab <- Bayes4Mixtures(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights, PlotIt = T) 
```

Wir passen die transformierte Daten mit 3 Gauss.

```{r GMM_plot_Precip, echo = FALSE,fig.cap = figNum("GMM für tranformierte Precipitation Daten ohne 0,0 und 0,1, 3 Gauss")}
Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))
PlotMixturesAndBoundaries(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights,SingleGausses=T, lwd=3)
```

```{r gmm_verification_plot_Precip, echo = FALSE, fig.cap = figNum("QQplot zur Verifizierung, Daten gegen GMM")}
#Verifizierung
Werte2 <- list(Means = c(126.0190, 429.6519, 712.7960), 
           SDs = c(121.8712, 122.5664, 135.4684), 
           Weights = c( 0.343, 0.224, 0.553))
QQplotGMM(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights)

```

Die Anpassung siegt auf den ersten Blick gut aus. Wir führen noch eine statistische Verifizierung durch.

```{r gmm_verification_statistik_test_Precip, echo = FALSE,fig.cap = figNum("Chi-Quadrat-Test. H0: Daten und GMM besitzen die gleiche Verteilung")}

abc <- Chi2testMixtures(transPrec, Werte2$Means, Werte2$SDs, Werte2$Weights, PlotIt = T)
```

P-Wert ist etwa 0.79, da der Stichprobenumfang(`r length(transPrec)`) sehr klein ist, wird $H_0$ nicht abgelehnt und wir nehmen die Anpassung gut an.

***
### Clusterung der Daten
Neben den zwei Gruppen der Nullen und 0,1 Werte, teilen wir die restlichen Daten in 3 Klassen auf: Niedrige, mittlere und hohe Precipation.

```{r clusterung_Precip, echo = FALSE, fig.cap = figNum("Clusterung nach GMM, 0 und 0,1 bilden sich jeweils als eine Gruppe")}
#Clusterung
dec <- BayesDecisionBoundaries(Werte2$Means, Werte2$SDs, Werte2$Weights)
Cls <- ClassifyByDecisionBoundaries(transPrec, dec)

ind <- which(Data[, 1] > 0.1)
ind2 <- which(Data[, 1] == 0)
ind3 <- which(Data[, 1] == 0.1)

plot(ind, Data[ind, 1], ylab = "Precipitation", xlab = "Zeit", col = Cls, main = "Clusterung", ylim = c(0,1))
points(ind2, Data[ind2, 1], col = "blue")
points(ind3, Data[ind3, 1], col = "pink")
abline(v = min(indy), col = 6, lwd = 3)
legend("topright", c("Hoch", "Mittel", "Niedrig","0,1", "0.0"), col = c("green", "red", "black", "pink","blue"), pch = 1)


detach(Prec)

```

***



